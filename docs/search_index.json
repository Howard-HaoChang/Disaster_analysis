[["index.html", "Disaster Analysis Chapter 1 Introduction", " Disaster Analysis Jiachen Liu Hao Chang Yihui Xie 2022-05-02 Chapter 1 Introduction As the pandemic grow rapidly after 2020 and developed a kind of stable pattern nowadays, it has a great influence on the human livings and other activities. Actually this is not the only disaster that had a great influence on humans’ live. There are several big disaster that are greatly recorded in the history. For example, the Valdivia Earthquake Strikes Chile, the Chernobyl nuclear disaster, the Indian Ocean Tsunami etc. They’ve all made a big damage on humans’ life as well as economic. We are interested in the disaster damage pattern in different region and different time. Is there any clustering patterns? Is there a inside seasonal pattern? Is there any relation between different disasters? These are all questions that researchers are interested in. We want to use data visualization method to have an intuitive understanding of these patterns. Also, as we want to know more about the pattern of Covid-19, for we can know about the real world based on this, we also want to compare the Covid-19 pattern and other disaster. It might give us a internal understanding of nowadays pandemic. "],["data-sources.html", "Chapter 2 Data sources 2.1 Disester Data 2.2 COVID Data 2.3 GDP Data", " Chapter 2 Data sources 2.1 Disester Data Our disaster Data is coming from The International Disaster Data Center for research on the Epidemiology of Disaster. We downloaded the dataset with default setting. The web page is as shown below: International Disaster Data Center Website EM-DAT contains essential core data on the occurrence and effects of over 22,000 mass disasters worldwide from 1900 to the present day. The source of the dataset is described as below, and hence high credibility. &gt; The database is compiled from various sources including UN, governmental and non-governmental agencies, insurance companies, research institutes and press agencies. As there can be conflicting information and figures, CRED has established a method of ranking these sources according to their ability to provide trustworthy and complete data. In the majority of cases, a disaster will only be entered into EM-DAT if at least two sources report the disaster’s occurrence in terms of deaths and/or affected persons. sprintf(&#39;The row number of disaster dataset is %.0f, and the column number is %.0f.&#39;, dim(Disaster)[1], dim(Disaster)[2]) ## [1] &quot;The row number of disaster dataset is 25516, and the column number is 50.&quot; # The Names including print(colnames(Disaster)) ## [1] &quot;Dis No&quot; ## [2] &quot;Year&quot; ## [3] &quot;Seq&quot; ## [4] &quot;Glide&quot; ## [5] &quot;Disaster Group&quot; ## [6] &quot;Disaster Subgroup&quot; ## [7] &quot;Disaster Type&quot; ## [8] &quot;Disaster Subtype&quot; ## [9] &quot;Disaster Subsubtype&quot; ## [10] &quot;Event Name&quot; ## [11] &quot;Country&quot; ## [12] &quot;ISO&quot; ## [13] &quot;Region&quot; ## [14] &quot;Continent&quot; ## [15] &quot;Location&quot; ## [16] &quot;Origin&quot; ## [17] &quot;Associated Dis&quot; ## [18] &quot;Associated Dis2&quot; ## [19] &quot;OFDA Response&quot; ## [20] &quot;Appeal&quot; ## [21] &quot;Declaration&quot; ## [22] &quot;Aid Contribution&quot; ## [23] &quot;Dis Mag Value&quot; ## [24] &quot;Dis Mag Scale&quot; ## [25] &quot;Latitude&quot; ## [26] &quot;Longitude&quot; ## [27] &quot;Local Time&quot; ## [28] &quot;River Basin&quot; ## [29] &quot;Start Year&quot; ## [30] &quot;Start Month&quot; ## [31] &quot;Start Day&quot; ## [32] &quot;End Year&quot; ## [33] &quot;End Month&quot; ## [34] &quot;End Day&quot; ## [35] &quot;Total Deaths&quot; ## [36] &quot;No Injured&quot; ## [37] &quot;No Affected&quot; ## [38] &quot;No Homeless&quot; ## [39] &quot;Total Affected&quot; ## [40] &quot;Reconstruction Costs (&#39;000 US$)&quot; ## [41] &quot;Reconstruction Costs, Adjusted (&#39;000 US$)&quot; ## [42] &quot;Insured Damages (&#39;000 US$)&quot; ## [43] &quot;Insured Damages, Adjusted (&#39;000 US$)&quot; ## [44] &quot;Total Damages (&#39;000 US$)&quot; ## [45] &quot;Total Damages, Adjusted (&#39;000 US$)&quot; ## [46] &quot;CPI&quot; ## [47] &quot;Adm Level&quot; ## [48] &quot;Admin1 Code&quot; ## [49] &quot;Admin2 Code&quot; ## [50] &quot;Geo Locations&quot; 2.2 COVID Data Our COVID data is from a repository from Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). We used only the deaths number and read the data directly from the repo. The dataset also supported by the ESRI Living Atlas Team and the Johns Hopkins University Applied Physics Lab (JHU APL), and subject is read in from the daily case report. The time series tables are subject to be updated if inaccuracies are identified in our historical data. sprintf(&#39;The row number of covid dataset is %.0f, and the column number is %.0f.&#39;, dim(COVID)[1], dim(COVID)[2]) ## [1] &quot;The row number of covid dataset is 284, and the column number is 835.&quot; # The Names including print(colnames(COVID)[1:20]) ## [1] &quot;Province.State&quot; &quot;Country.Region&quot; &quot;Lat&quot; &quot;Long&quot; ## [5] &quot;X1.22.20&quot; &quot;X1.23.20&quot; &quot;X1.24.20&quot; &quot;X1.25.20&quot; ## [9] &quot;X1.26.20&quot; &quot;X1.27.20&quot; &quot;X1.28.20&quot; &quot;X1.29.20&quot; ## [13] &quot;X1.30.20&quot; &quot;X1.31.20&quot; &quot;X2.1.20&quot; &quot;X2.2.20&quot; ## [17] &quot;X2.3.20&quot; &quot;X2.4.20&quot; &quot;X2.5.20&quot; &quot;X2.6.20&quot; # And all the later columns are time series data up to now. 2.3 GDP Data Our GDP data is downloaded from The World Bank. We used the world development indicators database, which is the primary World Bank collection of development indicators, compiled from officially recognized international sources. And it presents the most current and accurate global development data available, and includes national, regional and global estimates. As shown above, we include all Countries and Time(Years) available, and GDP is what we need. sprintf(&#39;The row number of GDP dataset is %.0f, and the column number is %.0f.&#39;, dim(GDP)[1], dim(GDP)[2]) ## [1] &quot;The row number of GDP dataset is 271, and the column number is 66.&quot; # The Names including print(colnames(GDP)[1:20]) ## [1] &quot;锘縎eries.Name&quot; &quot;Series.Code&quot; &quot;Country.Name&quot; &quot;Country.Code&quot; ## [5] &quot;X1960..YR1960.&quot; &quot;X1961..YR1961.&quot; &quot;X1962..YR1962.&quot; &quot;X1963..YR1963.&quot; ## [9] &quot;X1964..YR1964.&quot; &quot;X1965..YR1965.&quot; &quot;X1966..YR1966.&quot; &quot;X1967..YR1967.&quot; ## [13] &quot;X1968..YR1968.&quot; &quot;X1969..YR1969.&quot; &quot;X1970..YR1970.&quot; &quot;X1971..YR1971.&quot; ## [17] &quot;X1972..YR1972.&quot; &quot;X1973..YR1973.&quot; &quot;X1974..YR1974.&quot; &quot;X1975..YR1975.&quot; # And all the later columns are time series data up to now. "],["data-transformation.html", "Chapter 3 Data transformation 3.1 Disaster Data 3.2 Covid Data 3.3 GDP time series data 3.4 latitude longtitude data", " Chapter 3 Data transformation ## Warning: package &#39;countrycode&#39; was built under R version 4.1.3 3.1 Disaster Data # Load disaster data and map message data raw_data &lt;- readxl::read_xlsx(&quot;data/emdat_public_2022_04_30_full.xlsx&quot;) latitude.longtitude.data &lt;- map_data(&quot;world&quot;) We want to add location information to disaster data for graphical visualization. However, due to the large time span of our data, some countries have experienced splitting or merging in this 100-year period, so in order to ensure that our data can be merged with the data of geographic information through the country name, we need to clean our countries’ names first before doing the merge. 3.1.1 checking the country name # Apply the countryname function to standardize the countryname of each dataset countryname(unique(raw_data$Country)) countryname(unique(latitude.longtitude.data$region)) Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Azores Islands, Canary Is, Serbia Montenegro, Yemen P Dem Rep Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Ascension Island, Azores, Barbuda, Canary Islands, Chagos Archipelago, Grenadines, Heard Island, Madeira Islands, Micronesia, Saba, Saint Martin, Siachen Glacier, Sint Eustatius, Virgin Islands There are several reasons for mismatching: First situation, the countries are too small to be included in the package.(e.g. “Tuvalu”, “Micronesia (Federated States of)”) Second situation, the countries are no longer exist since our data contains data from 1900. (e.g. “Serbia Montenegro”, “Yemen P Dem Rep”) “Yemen P Dem Rep” merged with “Yemen Arab Rep” in 1990 and is called “Yemen” now. Third situation, this does not show up here, but we need to consider the situation that some of the countries disintegrated during the past 122 years. (e.g. “Czechoslovakia”, “Yugoslavia”) In this situation, we may need to change the data of one country into several. “Serbia Montenegro” split into two countries called “Serbia” and “Montengro” in 2006. “Yugoslavia” had split into six countries,“Slovenia”,“Croatia”, “Serbia”, “Montengro”, “Bosnia and Herzegovina” and “Macedonia”. “Czechoslovakia” had split into two countries, “Czech Republic” and “Slovakia”, in 1993. 3.1.2 Manual Adjustments Based on the above three situation, we did some manual adjustment(splitting) on our data, and reread in the data. Our splited countries are：“Czechoslovakia”， “Yugoslavia”，and “Serbia Montenegro”. # data after splitting certain countries data_temp &lt;- readxl::read_xlsx(&quot;data/disaster data.xlsx&quot;) # some manual adjustments # delete &quot;Micronesia (Federated States of)&quot; and &quot;Tuvalu&quot;, which does not included in the existing data, hence do not have latitude and longitude information. data_remove &lt;- data_temp[-which(data_temp$Country %in% c(&quot;Micronesia (Federated States of)&quot;,&quot;Tuvalu&quot;)),] # manual match some small contries: Azores Islands - Azores; Canary Is - Canary Islands data_remove$Country[data_remove$Country == &quot;Azores Islands&quot;] &lt;- &quot;Azores&quot; data_remove$Country[data_remove$Country == &quot;Canary Is&quot;] &lt;- &quot;Canary Islands&quot; # merge &quot;Yemen P Dem Rep&quot; and &quot;Yemen Arab Rep&quot; data_remove$Country[data_remove$Country %in% c(&quot;Yemen P Dem Rep&quot;,&quot;Yemen Arab Rep&quot;)] &lt;- &quot;Yemen&quot; # Virgin Islands are one area in existing data, so merge together: Virgin Island (British) &amp; Virgin Island (U.S.) - Virgin Islands data_remove$Country[data_remove$Country == &quot;Virgin Island (British)&quot;] &lt;- &quot;Virgin Islands&quot; data_remove$Country[data_remove$Country == &quot;Virgin Island (U.S.)&quot;] &lt;- &quot;Virgin Islands&quot; # &quot;Hong Kong&quot; and &quot;Macao&quot; belong to China now data_remove$Country[data_remove$Country == &quot;Hong Kong&quot;] &lt;- &quot;China&quot; data_remove$Country[data_remove$Country == &quot;Macao&quot;] &lt;- &quot;China&quot; # &quot;Netherlands Antilles&quot; belongs to &quot;Caribbean Netherlands&quot;, but does not have independent geographic information, so including it in &quot;Netherlands&quot; data_remove$Country[data_remove$Country == &quot;Netherlands Antilles&quot;] &lt;- &quot;Netherlands&quot; # same situation, including &quot;Saint Martin (French part)&quot; in &quot;Saint Martin&quot; data_remove$Country[data_remove$Country == &quot;Saint Martin (French Part)&quot;] &lt;- &quot;Saint Martin&quot; # &quot;Tokelau&quot; is belong to &quot;New Zealand&quot; data_remove$Country[data_remove$Country == &quot;Tokelau&quot;] &lt;- &quot;New Zealand&quot; # Replace the column &quot;Country&quot; with the standard country names, and when mismatch then the country must be one of our adjusted countries, so just keep it as it is. disaster_match &lt;- data_remove %&gt;% mutate(Country = ifelse(is.na(countryname(data_remove$Country)),data_remove$Country,countryname(data_remove$Country))) #The data frame has a total of 50 variables, but we won&#39;t use all of them, so we need to tidy the data. disaster &lt;- disaster_match %&gt;% select(&quot;Year&quot;,&quot;Disaster Group&quot;,&quot;Disaster Subgroup&quot;,&quot;Disaster Type&quot;,&quot;Disaster Subtype&quot;,&quot;Country&quot;,&quot;ISO&quot;,&quot;Region&quot;, &quot;Continent&quot;,&quot;Total Deaths&quot;,&quot;Total Damages (&#39;000 US$)&quot;,&quot;Total Damages, Adjusted (&#39;000 US$)&quot;) colnames(disaster) &lt;- c(&quot;Year&quot;,&quot;Disaster Group&quot;,&quot;Disaster Subgroup&quot;,&quot;Disaster Type&quot;,&quot;Disaster Subtype&quot;,&quot;Country&quot;,&quot;ISO&quot;,&quot;Region&quot;,&quot;Continent&quot;,&quot;Total Deaths&quot;,&quot;Total Damages&quot;,&quot;Total Damages Adjusted&quot;) 3.2 Covid Data The number of deaths in this data is refreshed daily in the last column and is cumulative so we only need to keep the last column for the number of deaths in each country. Because some countries count the number of deaths according to different cities, we need to add up the number of deaths in different cities in each country and combine them into the total number of deaths in a country. #Loading covid data df_covid_raw = read.csv(&#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39;) covid_df = df_covid_raw %&gt;% select(ncol(df_covid_raw)) covid_df = cbind(&quot;Country.Region&quot; = df_covid_raw$Country.Region, &quot;Total.Death&quot; = rowSums(covid_df)) %&gt;% data.frame() covid_df = covid_df %&gt;% mutate(&quot;Total.Death&quot; = as.numeric(Total.Death)) %&gt;% group_by(Country.Region) %&gt;% summarise(&quot;Total.Death&quot; = sum(Total.Death, na.rm = T)) In order to compare the data together, we also need to unify the country names of the data according to the corrected disaster data. #Apply the countryname function to standardize the countryname of dataset countryname(unique(covid_df$Country.Region)) Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Diamond Princess, Micronesia, MS Zaandam, Summer Olympics 2020, Winter Olympics 2022 # remove Summer Olympics 2020 &amp; Winter Olympics 2022,Micronesia covid_remove &lt;- covid_df[-which(covid_df$Country.Region %in% c(&quot;Summer Olympics 2020&quot;, &quot;Winter Olympics 2022&quot;, &quot;Micronesia&quot;)),] # Diamond Princess is a Japanese cruise ship, so it counts as Japan covid_remove$Country.Region[covid_remove$Country.Region == &quot;Diamond Princess&quot;] &lt;- &quot;Japan&quot; # MS Zaandam is a Netherlands cruise ship, so it counts as Netherlands covid_remove$Country.Region[covid_remove$Country.Region == &quot;MS Zaandam&quot;] &lt;- &quot;Netherlands&quot; # adding a column called &quot;country.name&quot; to be the standard country names, and when mismatch then the country must be one of our adjusted countries, so just keep it as it is. covid_match &lt;- covid_remove %&gt;% mutate(country.name = ifelse(is.na(countryname(covid_remove$Country.Region)),covid_remove$Country.Region,countryname(covid_remove$Country.Region))) 3.3 GDP time series data # Load the GDP raw data GDP_temp = read.csv(&quot;data/world_bank_gdp.csv&quot;) The country name of this data set contains two parts, which is the names of difference countries and different regions. We only consider about the time series data of the country so we delete the country name of different regions. Also, the name of time series variables is not beautiful so we also change the variable name that makes it look more properly. # We only need the country name, country code and time series data GDP &lt;- GDP_temp[c(1:which(GDP$Country.Name == &quot;Zimbabwe&quot;)),-c(1,2)] The missing value of this data is not represented by NULL or NA, but by “..”. This is not convenient for our subsequent data reference and processing, so we directly use Excel to convert all “..” into NULL. # Load the GDP with missing value expressed by NULL GDP = read.csv(&quot;data/GDP.csv&quot;) We want to add a location information to this data so we need to unify the country names. GDP &lt;- GDP %&gt;% mutate(Country.Name = ifelse(is.na(countryname(GDP$Country.Name)),GDP$Country.Name,countryname(GDP$Country.Name))) ## Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Cura莽ao, C么te d鈥橧voire, S茫o Tom茅 &amp; Pr铆ncipe ## Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Cura莽ao, C么te d鈥橧voire, S茫o Tom茅 &amp; Pr铆ncipe 3.4 latitude longtitude data Although the country name of this data is sufficiently standardized, in order for all the data to match each other, we also need to modify the country name. # Load the data latitude.longtitude.data &lt;- map_data(&quot;world&quot;) # # adding a column called &quot;Country&quot; to be the standard country names, and when mismatch then the country must be one of our adjusted countries, so just keep it as it is. map_match &lt;- latitude.longtitude.data %&gt;% mutate(Country = ifelse(is.na(countryname(latitude.longtitude.data$region)),latitude.longtitude.data$region,countryname(latitude.longtitude.data$region))) %&gt;% select(long,lat,group,order,Country,subregion) "],["missing-values.html", "Chapter 4 Missing values 4.1 Disaster dataset 4.2 Covid Dataset 4.3 GDP Dataset", " Chapter 4 Missing values 4.1 Disaster dataset disaster = read.csv(&quot;data/disaster_missing.csv&quot;) %&gt;% select(-X) 4.1.1 By row rowSums(is.na(disaster)) %&gt;% sort(decreasing = TRUE) %&gt;% table() ## . ## 0 1 2 3 4 ## 3555 1748 14669 4781 742 It shows that the missing value numbers with different rows. There are for 3555 rows with no missing values, 1748 rows with 1 missing values, 14669 rows with 2 missing values, 4781 rows with 3 missing values and 742 rows with 4 missing values. Also we want to visualize it by year. missing &lt;- disaster %&gt;% group_by(Year) %&gt;% summarise(sum.na = sum(is.na(Total.Deaths)+is.na(Total.Damages)+is.na(Disaster.Subtype)+is.na(Total.Damages.Adjusted))) ggplot(missing, aes(x = Year, y = sum.na)) + geom_col(color = &quot;blue&quot;, fill = &quot;lightblue&quot;) + ggtitle(&quot;Number of missing values by Year&quot;) + xlab(&quot;&quot;) + ylab(&quot;Number of missing station values(All Variables)&quot;) + theme(axis.text.x = element_text(angle = 45)) + scale_x_discrete(breaks = c(&#39;1900&#39;,&#39;1910&#39;,&#39;1920&#39;,&#39;1930&#39;,&#39;1940&#39;,&#39;1950&#39;,&#39;1960&#39;,&#39;1970&#39;,&#39;1980&#39;,&#39;1990&#39;,&#39;2000&#39;,&#39;2010&#39;,&#39;2020&#39;)) It shows that the missing value has a increasing trend among all years because the data records are increasing over year. 4.1.2 By Column colSums(is.na(disaster)) %&gt;% sort(decreasing = TRUE) ## Total.Damages.Adjusted Total.Damages Total.Deaths ## 19931 19917 5334 ## Disaster.Subtype Year Disaster.Group ## 3215 0 0 ## Disaster.Subgroup Disaster.Type Country ## 0 0 0 ## ISO Region Continent ## 0 0 0 plot_missing(disaster, percent = FALSE) It shows that damage and adj.damage gets the most nas, then deaths and subtype. 4.1.3 By Value tidydata &lt;- disaster %&gt;% rownames_to_column(&quot;id&quot;) %&gt;% gather(key, value, -id) %&gt;% mutate(missing = ifelse(is.na(value), &quot;yes&quot;, &quot;no&quot;)) ggplot(tidydata, aes(x = key, y = fct_rev(id), fill = missing)) + geom_tile() + ggtitle(&quot;ourdata with NAs&quot;) + scale_fill_viridis_d() + # discrete scale theme_bw()+ scale_y_discrete(breaks = c()) It gives a look at the na for each value. However I don’t think that there is a relation between the nas in different variable. 4.2 Covid Dataset covid = read.csv(&quot;data/covid.csv&quot;) %&gt;% select(-X) sum(is.na(covid)) ## [1] 0 There is no NA value in this data set. 4.3 GDP Dataset GDP = read.csv(&quot;data/GDP.csv&quot;) This is a time series data from 1960 to 2020 for the countries around the world, we want to check the na for each countries and for each Year. 4.3.1 For countries We want to see how many NA are there for each country missing = cbind(GDP[,1:2], NAs = rowSums(matrix(as.numeric(is.na(GDP[,-c(1,2)])), nrow = nrow(GDP)))) %&gt;% arrange(desc(NAs)) head(missing, 10) ## X Country.Name NAs ## 1 28 British Virgin Islands 61 ## 2 76 Gibraltar 61 ## 3 104 North Korea 61 ## 4 184 Saint Martin (French part) 61 ## 5 173 Sint Maarten 53 ## 6 179 South Sudan 53 ## 7 40 Channel Islands 51 ## 8 51 Cura莽ao 51 ## 9 138 Nauru 50 ## 10 106 Kosovo 48 As we can see, the missing value are tend to appear on those small countries where data are hard to collect. 4.3.2 For Year Now we want to know the missing value among time missing = cbind(Year = 1960:2020, NAs = colSums(matrix(as.numeric(is.na(GDP[,-c(1,2)])), nrow = nrow(GDP)))) ## Warning in cbind(Year = 1960:2020, NAs = colSums(matrix(as.numeric(is.na(GDP[, : ## number of rows of result is not a multiple of vector length (arg 1) plot(missing, main = &#39;Missing values among year&#39;) Here as we can see, the missing values are reducing with the year increase. That’s because with the development of the technology, we have more and easier access to collect the data. "],["results.html", "Chapter 5 Results", " Chapter 5 Results "],["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component disaster = read.csv(&#39;data/disaster.csv&#39;) %&gt;% select(-X) mapdata = read.csv(&#39;data/Location.csv&#39;) %&gt;% select(-X) disaster_raw = disaster %&gt;% group_by(Year,Country) %&gt;% summarize(deaths = sum(Total.Deaths, na.rm = T), damage = sum(Total.Damages, na.rm = T), damageadj = sum(Total.Damages.Adjusted, na.rm = T)) %&gt;% unique() ## `summarise()` has grouped output by &#39;Year&#39;. You can override using the ## `.groups` argument. country = sort(unique(mapdata$Country)) data = data.frame(Year = as.character(rep(seq(1900,2022), each = length(country))), Country = rep(country, 123)) data$Year = as.numeric(data$Year) data1 = data %&gt;% left_join(disaster_raw) ## Joining, by = c(&quot;Year&quot;, &quot;Country&quot;) data1[is.na(data1)] = 0 rawdata = left_join(mapdata,data1,by=c(&quot;Country&quot; = &quot;Country&quot;)) rawdata$Year = as.numeric(rawdata$Year) g2 = ggplot(rawdata, aes(x = long, y = lat, group = group))+ # the same as the setting with summary plot geom_polygon(aes(fill = log10(deaths)), color = &#39;black&#39;)+ transition_manual(frames = Year) + # use year as the animation parameter scale_fill_gradient(low = &#39;#FFF68F&#39;,high = &#39;#FC4902&#39;) + labs(title = paste(&#39;Year:&#39;,&#39;{current_frame}&#39;)) + # make the title changes among different plot ggdark::dark_theme_bw() ## Inverted geom defaults of fill and color/colour. ## To change them back, use invert_geom_defaults(). animate(g2,fps = 3) g3 = ggplot(rawdata, aes(x = long, y = lat, group = group))+ # the same as the setting with summary plot geom_polygon(aes(fill = log10(damageadj)), color = &#39;black&#39;)+ transition_manual(frames = Year) + # use year as the animation parameter scale_fill_gradient(low = &#39;#FFF68F&#39;,high = &#39;#FC4902&#39;) + labs(title = paste(&#39;Year:&#39;,&#39;{current_frame}&#39;)) + # make the title changes among different plot ggdark::dark_theme_bw() animate(g3,fps = 3) "],["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion "]]
