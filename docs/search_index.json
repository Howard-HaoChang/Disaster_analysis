[["index.html", "Disaster Analysis Chapter 1 Introduction", " Disaster Analysis Jiachen Liu Hao Chang Yihui Xie 2022-05-04 Chapter 1 Introduction As the pandemic grow rapidly after 2020 and developed a kind of stable pattern nowadays, it has a great influence on the human livings and other activities. Actually this is not the only disaster that had a great influence on humans live. There are several big disaster that are greatly recorded in the history. For example, the Valdivia Earthquake Strikes Chile, the Chernobyl nuclear disaster, the Indian Ocean Tsunami etc. Theyve all made a big damage on humans life as well as economic. We are interested in the disaster damage pattern in different region and different time. Is there any clustering patterns? Is there a inside seasonal pattern? Is there any relation between different disasters? These are all questions that researchers are interested in. We want to use data visualization method to have an intuitive understanding of these patterns. Also, as we want to know more about the pattern of Covid-19, for we can know about the real world based on this, we also want to compare the Covid-19 pattern and other disaster. It might give us a internal understanding of nowadays pandemic. "],["data-sources.html", "Chapter 2 Data sources 2.1 Disester Data 2.2 COVID Data 2.3 GDP Data", " Chapter 2 Data sources 2.1 Disester Data Our disaster Data is coming from The International Disaster Data Center for research on the Epidemiology of Disaster. We downloaded the dataset with default setting. The web page is as shown below: International Disaster Data Center Website EM-DAT contains essential core data on the occurrence and effects of over 22,000 mass disasters worldwide from 1900 to the present day. The source of the dataset is described as below, and hence high credibility. &gt; The database is compiled from various sources including UN, governmental and non-governmental agencies, insurance companies, research institutes and press agencies. As there can be conflicting information and figures, CRED has established a method of ranking these sources according to their ability to provide trustworthy and complete data. In the majority of cases, a disaster will only be entered into EM-DAT if at least two sources report the disasters occurrence in terms of deaths and/or affected persons. sprintf(&#39;The row number of disaster dataset is %.0f, and the column number is %.0f.&#39;, dim(Disaster)[1], dim(Disaster)[2]) ## [1] &quot;The row number of disaster dataset is 25516, and the column number is 50.&quot; # The Names including print(colnames(Disaster)) ## [1] &quot;Dis No&quot; ## [2] &quot;Year&quot; ## [3] &quot;Seq&quot; ## [4] &quot;Glide&quot; ## [5] &quot;Disaster Group&quot; ## [6] &quot;Disaster Subgroup&quot; ## [7] &quot;Disaster Type&quot; ## [8] &quot;Disaster Subtype&quot; ## [9] &quot;Disaster Subsubtype&quot; ## [10] &quot;Event Name&quot; ## [11] &quot;Country&quot; ## [12] &quot;ISO&quot; ## [13] &quot;Region&quot; ## [14] &quot;Continent&quot; ## [15] &quot;Location&quot; ## [16] &quot;Origin&quot; ## [17] &quot;Associated Dis&quot; ## [18] &quot;Associated Dis2&quot; ## [19] &quot;OFDA Response&quot; ## [20] &quot;Appeal&quot; ## [21] &quot;Declaration&quot; ## [22] &quot;Aid Contribution&quot; ## [23] &quot;Dis Mag Value&quot; ## [24] &quot;Dis Mag Scale&quot; ## [25] &quot;Latitude&quot; ## [26] &quot;Longitude&quot; ## [27] &quot;Local Time&quot; ## [28] &quot;River Basin&quot; ## [29] &quot;Start Year&quot; ## [30] &quot;Start Month&quot; ## [31] &quot;Start Day&quot; ## [32] &quot;End Year&quot; ## [33] &quot;End Month&quot; ## [34] &quot;End Day&quot; ## [35] &quot;Total Deaths&quot; ## [36] &quot;No Injured&quot; ## [37] &quot;No Affected&quot; ## [38] &quot;No Homeless&quot; ## [39] &quot;Total Affected&quot; ## [40] &quot;Reconstruction Costs (&#39;000 US$)&quot; ## [41] &quot;Reconstruction Costs, Adjusted (&#39;000 US$)&quot; ## [42] &quot;Insured Damages (&#39;000 US$)&quot; ## [43] &quot;Insured Damages, Adjusted (&#39;000 US$)&quot; ## [44] &quot;Total Damages (&#39;000 US$)&quot; ## [45] &quot;Total Damages, Adjusted (&#39;000 US$)&quot; ## [46] &quot;CPI&quot; ## [47] &quot;Adm Level&quot; ## [48] &quot;Admin1 Code&quot; ## [49] &quot;Admin2 Code&quot; ## [50] &quot;Geo Locations&quot; 2.2 COVID Data Our COVID data is from a repository from Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). We used only the deaths number and read the data directly from the repo. The dataset also supported by the ESRI Living Atlas Team and the Johns Hopkins University Applied Physics Lab (JHU APL), and subject is read in from the daily case report. The time series tables are subject to be updated if inaccuracies are identified in our historical data. sprintf(&#39;The row number of covid dataset is %.0f, and the column number is %.0f.&#39;, dim(COVID)[1], dim(COVID)[2]) ## [1] &quot;The row number of covid dataset is 284, and the column number is 837.&quot; # The Names including print(colnames(COVID)[1:20]) ## [1] &quot;Province.State&quot; &quot;Country.Region&quot; &quot;Lat&quot; &quot;Long&quot; ## [5] &quot;X1.22.20&quot; &quot;X1.23.20&quot; &quot;X1.24.20&quot; &quot;X1.25.20&quot; ## [9] &quot;X1.26.20&quot; &quot;X1.27.20&quot; &quot;X1.28.20&quot; &quot;X1.29.20&quot; ## [13] &quot;X1.30.20&quot; &quot;X1.31.20&quot; &quot;X2.1.20&quot; &quot;X2.2.20&quot; ## [17] &quot;X2.3.20&quot; &quot;X2.4.20&quot; &quot;X2.5.20&quot; &quot;X2.6.20&quot; And all the later columns are time series data up to now. Each column represent the total death number up to that day. 2.3 GDP Data Our GDP data is downloaded from The World Bank. We used the world development indicators database, which is the primary World Bank collection of development indicators, compiled from officially recognized international sources. And it presents the most current and accurate global development data available, and includes national, regional and global estimates. As shown above, we include all Countries and Time(Years) available, and GDP is what we need. sprintf(&#39;The row number of GDP dataset is %.0f, and the column number is %.0f.&#39;, dim(GDP)[1], dim(GDP)[2]) ## [1] &quot;The row number of GDP dataset is 271, and the column number is 66.&quot; # The Names including print(colnames(GDP)[1:20]) ## [1] &quot;ï..Series.Name&quot; &quot;Series.Code&quot; &quot;Country.Name&quot; &quot;Country.Code&quot; ## [5] &quot;X1960..YR1960.&quot; &quot;X1961..YR1961.&quot; &quot;X1962..YR1962.&quot; &quot;X1963..YR1963.&quot; ## [9] &quot;X1964..YR1964.&quot; &quot;X1965..YR1965.&quot; &quot;X1966..YR1966.&quot; &quot;X1967..YR1967.&quot; ## [13] &quot;X1968..YR1968.&quot; &quot;X1969..YR1969.&quot; &quot;X1970..YR1970.&quot; &quot;X1971..YR1971.&quot; ## [17] &quot;X1972..YR1972.&quot; &quot;X1973..YR1973.&quot; &quot;X1974..YR1974.&quot; &quot;X1975..YR1975.&quot; All the later columns are time series data up to now. "],["data-transformation.html", "Chapter 3 Data transformation 3.1 Disaster Data 3.2 Covid Data 3.3 GDP time series data 3.4 latitude longtitude data", " Chapter 3 Data transformation 3.1 Disaster Data # Load disaster data and map message data raw_data &lt;- readxl::read_xlsx(&quot;data/emdat_public_2022_04_30_full.xlsx&quot;) latitude.longtitude.data &lt;- map_data(&quot;world&quot;) We want to add location information to disaster data for graphical visualization. However, due to the large time span of our data, some countries have experienced splitting or merging in this 100-year period, so in order to ensure that our data can be merged with the data of geographic information through the country name, we need to clean our countries names first before doing the merge. 3.1.1 checking the country name # Apply the countryname function to standardize the countryname of each dataset countryname(unique(raw_data$Country)) countryname(unique(latitude.longtitude.data$region)) Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Azores Islands, Canary Is, Serbia Montenegro, Yemen P Dem Rep Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Ascension Island, Azores, Barbuda, Canary Islands, Chagos Archipelago, Grenadines, Heard Island, Madeira Islands, Micronesia, Saba, Saint Martin, Siachen Glacier, Sint Eustatius, Virgin Islands There are several reasons for mismatching: First situation, the countries are too small to be included in the package.(e.g. Tuvalu, Micronesia (Federated States of)) Second situation, the countries are no longer exist since our data contains data from 1900. (e.g. Serbia Montenegro, Yemen P Dem Rep) Yemen P Dem Rep merged with Yemen Arab Rep in 1990 and is called Yemen now. Third situation, this does not show up here, but we need to consider the situation that some of the countries disintegrated during the past 122 years. (e.g. Czechoslovakia, Yugoslavia) In this situation, we may need to change the data of one country into several. Serbia Montenegro split into two countries called Serbia and Montengro in 2006. Yugoslavia had split into six countries,Slovenia,Croatia, Serbia, Montengro, Bosnia and Herzegovina and Macedonia. Czechoslovakia had split into two countries, Czech Republic and Slovakia, in 1993. 3.1.2 Manual Adjustments Based on the above three situation, we did some manual adjustment(splitting) on our data, and reread in the data. Our split countries areCzechoslovakia Yugoslaviaand Serbia Montenegro. # data after splitting certain countries data_temp &lt;- readxl::read_xlsx(&quot;data/disaster data.xlsx&quot;) # some manual adjustments # delete &quot;Micronesia (Federated States of)&quot; and &quot;Tuvalu&quot;, which does not included in the existing data, hence do not have latitude and longitude information. data_remove &lt;- data_temp[-which(data_temp$Country %in% c(&quot;Micronesia (Federated States of)&quot;,&quot;Tuvalu&quot;)),] # manual match some small contries: Azores Islands - Azores; Canary Is - Canary Islands data_remove$Country[data_remove$Country == &quot;Azores Islands&quot;] &lt;- &quot;Azores&quot; data_remove$Country[data_remove$Country == &quot;Canary Is&quot;] &lt;- &quot;Canary Islands&quot; # merge &quot;Yemen P Dem Rep&quot; and &quot;Yemen Arab Rep&quot; data_remove$Country[data_remove$Country %in% c(&quot;Yemen P Dem Rep&quot;,&quot;Yemen Arab Rep&quot;)] &lt;- &quot;Yemen&quot; # Virgin Islands are one area in existing data, so merge together: Virgin Island (British) &amp; Virgin Island (U.S.) - Virgin Islands data_remove$Country[data_remove$Country == &quot;Virgin Island (British)&quot;] &lt;- &quot;Virgin Islands&quot; data_remove$Country[data_remove$Country == &quot;Virgin Island (U.S.)&quot;] &lt;- &quot;Virgin Islands&quot; # &quot;Hong Kong&quot; and &quot;Macao&quot; belong to China now data_remove$Country[data_remove$Country == &quot;Hong Kong&quot;] &lt;- &quot;China&quot; data_remove$Country[data_remove$Country == &quot;Macao&quot;] &lt;- &quot;China&quot; # &quot;Netherlands Antilles&quot; belongs to &quot;Caribbean Netherlands&quot;, but does not have independent geographic information, so including it in &quot;Netherlands&quot; data_remove$Country[data_remove$Country == &quot;Netherlands Antilles&quot;] &lt;- &quot;Netherlands&quot; # same situation, including &quot;Saint Martin (French part)&quot; in &quot;Saint Martin&quot; data_remove$Country[data_remove$Country == &quot;Saint Martin (French Part)&quot;] &lt;- &quot;Saint Martin&quot; # &quot;Tokelau&quot; is belong to &quot;New Zealand&quot; data_remove$Country[data_remove$Country == &quot;Tokelau&quot;] &lt;- &quot;New Zealand&quot; # Replace the column &quot;Country&quot; with the standard country names, and when mismatch then the country must be one of our adjusted countries, so just keep it as it is. disaster_match &lt;- data_remove %&gt;% mutate(Country = ifelse(is.na(countryname(data_remove$Country)),data_remove$Country,countryname(data_remove$Country))) #The data frame has a total of 50 variables, but we won&#39;t use all of them, so we need to tidy the data. disaster &lt;- disaster_match %&gt;% select(&quot;Year&quot;,&quot;Disaster Group&quot;,&quot;Disaster Subgroup&quot;,&quot;Disaster Type&quot;,&quot;Disaster Subtype&quot;,&quot;Country&quot;,&quot;ISO&quot;,&quot;Region&quot;, &quot;Continent&quot;,&quot;Total Deaths&quot;,&quot;Total Damages (&#39;000 US$)&quot;,&quot;Total Damages, Adjusted (&#39;000 US$)&quot;) colnames(disaster) &lt;- c(&quot;Year&quot;,&quot;Disaster Group&quot;,&quot;Disaster Subgroup&quot;,&quot;Disaster Type&quot;,&quot;Disaster Subtype&quot;,&quot;Country&quot;,&quot;ISO&quot;,&quot;Region&quot;,&quot;Continent&quot;,&quot;Total Deaths&quot;,&quot;Total Damages&quot;,&quot;Total Damages Adjusted&quot;) 3.2 Covid Data The number of deaths in this data is refreshed daily in the last column and is cumulative so we only need to keep the last column for the number of deaths in each country. Because some countries count the number of deaths according to different cities, we need to add up the number of deaths in different cities in each country and combine them into the total number of deaths in a country. #Loading covid data df_covid_raw = read.csv(&#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39;) covid_df = df_covid_raw %&gt;% select(ncol(df_covid_raw)) covid_df = cbind(&quot;Country.Region&quot; = df_covid_raw$Country.Region, &quot;Total.Death&quot; = rowSums(covid_df)) %&gt;% data.frame() covid_df = covid_df %&gt;% mutate(&quot;Total.Death&quot; = as.numeric(Total.Death)) %&gt;% group_by(Country.Region) %&gt;% summarise(&quot;Total.Death&quot; = sum(Total.Death, na.rm = T)) In order to compare the data together, we also need to unify the country names of the data according to the corrected disaster data. #Apply the countryname function to standardize the countryname of dataset countryname(unique(covid_df$Country.Region)) Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Diamond Princess, Micronesia, MS Zaandam, Summer Olympics 2020, Winter Olympics 2022 # remove Summer Olympics 2020 &amp; Winter Olympics 2022,Micronesia covid_remove &lt;- covid_df[-which(covid_df$Country.Region %in% c(&quot;Summer Olympics 2020&quot;, &quot;Winter Olympics 2022&quot;, &quot;Micronesia&quot;)),] # Diamond Princess is a Japanese cruise ship, so it counts as Japan covid_remove$Country.Region[covid_remove$Country.Region == &quot;Diamond Princess&quot;] &lt;- &quot;Japan&quot; # MS Zaandam is a Netherlands cruise ship, so it counts as Netherlands covid_remove$Country.Region[covid_remove$Country.Region == &quot;MS Zaandam&quot;] &lt;- &quot;Netherlands&quot; # adding a column called &quot;country.name&quot; to be the standard country names, and when mismatch then the country must be one of our adjusted countries, so just keep it as it is. covid_match &lt;- covid_remove %&gt;% mutate(Country.Region = ifelse(is.na(countryname(covid_remove$Country.Region)),covid_remove$Country.Region,countryname(covid_remove$Country.Region))) 3.3 GDP time series data # Load the GDP raw data GDP_temp = read.csv(&quot;data/world_bank_gdp.csv&quot;) The country name of this data set contains two parts, which is the names of difference countries and different regions. We only consider about the time series data of the country so we delete the country name of different regions. Also, the name of time series variables is not beautiful so we also change the variable name that makes it look more properly. # We only need the country name, country code and time series data GDP &lt;- GDP_temp[c(1:which(GDP$Country.Name == &quot;Zimbabwe&quot;)),-c(1,2)] The missing value of this data is not represented by NULL or NA, but by ... This is not convenient for our subsequent data reference and processing, so we directly use Excel to convert all .. into NULL. # Load the GDP with missing value expressed by NULL GDP = read.csv(&quot;data/GDP.csv&quot;) We want to add a location information to this data so we need to unify the country names. GDP &lt;- GDP %&gt;% mutate(Country.Name = ifelse(is.na(countryname(GDP$Country.Name)),GDP$Country.Name,countryname(GDP$Country.Name))) ## Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: CuraÃ§ao, SÃ£o TomÃ© &amp; PrÃ­ncipe ## Warning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: CuraÃ§ao, SÃ£o TomÃ© &amp; PrÃ­ncipe 3.4 latitude longtitude data Although the country name of this data is sufficiently standardized, in order for all the data to match each other, we also need to modify the country name. # Load the data latitude.longtitude.data &lt;- map_data(&quot;world&quot;) # # adding a column called &quot;Country&quot; to be the standard country names, and when mismatch then the country must be one of our adjusted countries, so just keep it as it is. map_match &lt;- latitude.longtitude.data %&gt;% mutate(Country = ifelse(is.na(countryname(latitude.longtitude.data$region)),latitude.longtitude.data$region,countryname(latitude.longtitude.data$region))) %&gt;% select(long,lat,group,order,Country,subregion) "],["missing-values.html", "Chapter 4 Missing values 4.1 Disaster dataset 4.2 Covid Dataset 4.3 GDP Dataset", " Chapter 4 Missing values 4.1 Disaster dataset disaster = read.csv(&quot;data/disaster_missing.csv&quot;) %&gt;% select(-X) 4.1.1 By row rowSums(is.na(disaster)) %&gt;% sort(decreasing = TRUE) %&gt;% table() ## . ## 0 1 2 3 4 ## 3555 1748 14669 4781 742 It shows that the missing value numbers with different rows. There are for 3555 rows with no missing values, 1748 rows with 1 missing values, 14669 rows with 2 missing values, 4781 rows with 3 missing values and 742 rows with 4 missing values. Also we want to visualize it by year. missing &lt;- disaster %&gt;% group_by(Year) %&gt;% summarise(sum.na = sum(is.na(Total.Deaths)+is.na(Total.Damages)+is.na(Disaster.Subtype)+is.na(Total.Damages.Adjusted))) ggplot(missing, aes(x = Year, y = sum.na)) + geom_col(color = &quot;blue&quot;, fill = &quot;lightblue&quot;) + ggtitle(&quot;Number of missing values by Year&quot;) + xlab(&quot;&quot;) + ylab(&quot;Number of missing station values(All Variables)&quot;) + theme(axis.text.x = element_text(angle = 45)) + scale_x_discrete(breaks = c(&#39;1900&#39;,&#39;1910&#39;,&#39;1920&#39;,&#39;1930&#39;,&#39;1940&#39;,&#39;1950&#39;,&#39;1960&#39;,&#39;1970&#39;,&#39;1980&#39;,&#39;1990&#39;,&#39;2000&#39;,&#39;2010&#39;,&#39;2020&#39;)) It shows that the missing value has a increasing trend among all years because the data records are increasing over year. 4.1.2 By Column colSums(is.na(disaster)) %&gt;% sort(decreasing = TRUE) ## Total.Damages.Adjusted Total.Damages Total.Deaths ## 19931 19917 5334 ## Disaster.Subtype Year Disaster.Group ## 3215 0 0 ## Disaster.Subgroup Disaster.Type Country ## 0 0 0 ## ISO Region Continent ## 0 0 0 plot_missing(disaster, percent = FALSE) It shows that damage and adj.damage gets the most nas, then deaths and subtype. 4.1.3 By Value tidydata &lt;- disaster %&gt;% rownames_to_column(&quot;id&quot;) %&gt;% gather(key, value, -id) %&gt;% mutate(missing = ifelse(is.na(value), &quot;yes&quot;, &quot;no&quot;)) ggplot(tidydata, aes(x = key, y = fct_rev(id), fill = missing)) + geom_tile() + ggtitle(&quot;ourdata with NAs&quot;) + scale_fill_viridis_d() + # discrete scale theme_bw()+ scale_y_discrete(breaks = c()) It gives a look at the na for each value. However I dont think that there is a relation between the nas in different variable. 4.2 Covid Dataset covid = read.csv(&quot;data/covid.csv&quot;) %&gt;% select(-X) sum(is.na(covid)) ## [1] 0 There is no NA value in this data set. 4.3 GDP Dataset GDP = read.csv(&quot;data/GDP.csv&quot;) This is a time series data from 1960 to 2020 for the countries around the world, we want to check the na for each countries and for each Year. 4.3.1 For countries We want to see how many NA are there for each country missing = cbind(GDP[,1:2], NAs = rowSums(matrix(as.numeric(is.na(GDP[,-c(1,2)])), nrow = nrow(GDP)))) %&gt;% arrange(desc(NAs)) head(missing, 10) ## X Country.Name NAs ## 1 28 British Virgin Islands 61 ## 2 76 Gibraltar 61 ## 3 104 North Korea 61 ## 4 184 Saint Martin (French part) 61 ## 5 173 Sint Maarten 53 ## 6 179 South Sudan 53 ## 7 40 Channel Islands 51 ## 8 51 CuraÃ§ao 51 ## 9 138 Nauru 50 ## 10 106 Kosovo 48 As we can see, the missing value are tend to appear on those small countries where data are hard to collect. 4.3.2 For Year Now we want to know the missing value among time missing = cbind(Year = 1960:2020, NAs = colSums(matrix(as.numeric(is.na(GDP[,-c(1,2)])), nrow = nrow(GDP)))) ## Warning in cbind(Year = 1960:2020, NAs = colSums(matrix(as.numeric(is.na(GDP[, : ## number of rows of result is not a multiple of vector length (arg 1) plot(missing, main = &#39;Missing values among year&#39;) Here as we can see, the missing values are reducing with the year increase. Thats because with the development of the technology, we have more and easier access to collect the data. "],["results.html", "Chapter 5 Results 5.1 Disaster Data Exploration 5.2 COVID Data Exploration", " Chapter 5 Results 5.1 Disaster Data Exploration 5.1.1 Analysis of the relationship between number of disaster, Deaths and Damages In this section, we want to study the relationship between death and property damage and the number of disasters. We group and integrate the data according to the Disaster.Type in the data. Then do bar plot with Disaster.Type and sort from large to small for the number of disasters, the number of deaths and property damage. plot.data1 &lt;- disaster %&gt;% select(Disaster.Type,Total.Deaths,Total.Damages.Adjusted,Disaster.Group)%&gt;% group_by(Disaster.Group,Disaster.Type) %&gt;% summarize(Death = sum(Total.Deaths),Damages = sum(Total.Damages.Adjusted),Num.disaster = length(Total.Deaths)) %&gt;% ungroup() plot1.1 &lt;- plot.data1 %&gt;% mutate(Disaster.Type = fct_reorder(Disaster.Type, Num.disaster)) %&gt;% ggplot(aes(x=Disaster.Type, y=Num.disaster)) + geom_bar(stat=&quot;identity&quot;, width=.4) + coord_flip() + xlab(&quot;&quot;) + theme(axis.title.x=element_blank(),plot.margin = unit(c(1.5,1.5,1.5,1.5), &quot;lines&quot;)) plot1.2 &lt;- plot.data1 %&gt;% mutate(Disaster.Type = fct_reorder(Disaster.Type, Death)) %&gt;% ggplot( aes(x=Disaster.Type, y=Death)) + geom_bar(stat=&quot;identity&quot;, width=.4) + coord_flip() + xlab(&quot;&quot;) + theme(axis.title.x=element_blank(),plot.margin = unit(c(1.5,1.5,1.5,1.5), &quot;lines&quot;)) plot1.3 &lt;- plot.data1 %&gt;% mutate(Disaster.Type = fct_reorder(Disaster.Type, Damages)) %&gt;% ggplot(aes(x=Disaster.Type, y=Damages)) + geom_bar(stat=&quot;identity&quot;, width=.4) + coord_flip() + xlab(&quot;&quot;) + theme(axis.title.x=element_blank(),plot.margin = unit(c(1.5,1.5,1.5,1.5), &quot;lines&quot;)) plot_grid(plot1.1,plot1.2,plot1.3,ncol = 1,align = &quot;hv&quot;,labels = c(&quot;Disaster frequency over Countries (plot 1)&quot;,&quot;Disaster Deaths over Countries (plot 2)&quot;,&quot;Disaster Damages over Countries (plot 3)&quot;),hjust = -0.5,vjust =1.2) The plot 1 is a bar plot of the frequency of disasters. We can see that there are three orders of magnitude for the number of disasters. The first magnitude exceeded the other disasters by more than three times, and they were Transport accident, Flood and Storm. There are four kinds of disasters in the second magnitude, the values between them are very similar and more than twice the number of remaining disasters, they are earthquake, industrial accident, miscellaneous accident and epidemic. There are 12 catastrophes in the last magnitude, all of which occur relatively infrequently. The plot2 is a bar chart of the number of deaths caused by a disaster. We can see that there are many disasters with very few or even zero deaths, so we only observed six disasters with significant numbers. They are Drought, Epidemic, Flood, Complex Disaster, Earthquake and Storm. Comparing the plot1 disaster frequency chart, we will find that the above five disasters do not completely belong to the first two orders of magnitude, and the frequency of complex disasters and droughts is actually much lower than that of the other three disasters. So we can think that deaths are not completely positively correlated with the frequency of disasters The figure above is a bar chart of economic losses caused by a disaster. We can see that there are many disasters with little or no economic loss, so we only observed three very significant disasters and four relatively significant disasters. Very notable disasters are storms, floods and earthquakes. Relatively notable disasters are droughts, wildfires, extreme temperatures, and industrial accidents. Comparing to the plot2 disaster death map, we will find that except for floods and earthquakes, disasters that cause a large number of deaths are not necessarily accompanied by high economic losses. Comparing the plot1 disaster frequency map, we will find that floods, storms, earthquakes and industrial accidents are indeed frequent disasters, and most of these disasters that cause high economic losses are natural disasters. cols &lt;- character(nrow(plot.data1)) cols[] &lt;- &quot;black&quot; cols[plot.data1$Disaster.Group == &quot;Natural&quot;] &lt;- &quot;blue&quot; cols[plot.data1$Disaster.Group == &quot;Technological&quot;] &lt;- &quot;red&quot; cols[plot.data1$Disaster.Group == &quot;Complex Disasters&quot;] &lt;- &quot;orange&quot; plot.data1.1 &lt;- plot.data1 %&gt;% select(Disaster.Group,Death,Damages,Num.disaster) %&gt;% group_by(Disaster.Group) %&gt;% mutate(Death = log10(Death),Damages = log10(Damages),&#39;Disaster Frequency&#39; = log10(Num.disaster)) %&gt;% ungroup() pairs(plot.data1.1[,c(2,3,5)],main = &quot;Correlation Scatterplot&quot;,col=cols,pch=19) In order to further verify the relationship between disaster frequency and death and economic loss, we have drawn a pairwise plot, in which blue points represent natural disasters, red points represent technological disasters, and orange points represent complex disasters. . Through this figure, we can find that there is a certain correlation trend among the frequency of disasters, deaths and economic losses. target.Country = c(&#39;China&#39;,&#39;US&#39;,&#39;Russia&#39;,&#39;India&#39;,&#39;Brazil&#39;,&#39;Japan&#39;,&#39;France&#39;,&#39;Italy&#39;,&#39;South Africa&#39;,&#39;Egypt&#39;) plot.data2 &lt;- disaster %&gt;% filter(Country %in% target.Country) %&gt;% filter(Disaster.Group %in% c(&quot;Natural&quot;,&quot;Technological&quot;)) %&gt;% group_by(Country,Disaster.Group) %&gt;% summarize(Death = log(sum(Total.Deaths)),Damages = log(sum(Total.Damages.Adjusted)),&#39;Disaster Frequency&#39; = log(length(Total.Deaths))) colnames(plot.data2) &lt;- c(&quot;Country&quot;,&quot;Disaster Group&quot;,&quot;Death&quot;,&quot;Damages&quot;,&quot;Disaster Frequency&quot;) parcoords(plot.data2, color = list( colorBy = &quot;Disaster Group&quot;, colorScale = &quot;scaleOrdinal&quot;, colorScheme = &quot;schemeCategory10&quot;), rownames = F, brushMode = &quot;1D-axes&quot;, reorderable = T, queue = T, withD3 = T) To further verify our conclusions, we selected ten typical countries for further analysis, they are China, US, Russia, India, Brazil, Japan, France,  Italy, South Africa and Egypt. Among them, we chooseChina, US, Russia, India, Japan, France, Italy because these countries are relatively significant points in the previous scatter plot analysis. The choice of South Africa and Egypt is because South America and Africa are vast and have large populations, so we selected the countries that are representative of the continent for analysis. We calculated deaths, economic losses and disaster frequencies for these ten typical countries according to different types of disasters and used these data to make interactive parallel coordinates plots. Through the above figure, we can find that there are certain clusters of deaths caused by technological disasters , and the deaths caused by natural disasters are very scattered. Moreover, the economic losses caused by technological disasters are often smaller than those caused by natural disasters. We think this may be related to the fact that technological disasters are generally smaller in scale than natural disasters. disaster = read.csv(&#39;data/disaster.csv&#39;) %&gt;% select(-X) mapdata = read.csv(&#39;data/Location.csv&#39;) %&gt;% select(-X) disaster_raw = disaster %&gt;% group_by(Year,Country) %&gt;% summarize(deaths = sum(Total.Deaths, na.rm = T), damage = sum(Total.Damages, na.rm = T), damageadj = sum(Total.Damages.Adjusted, na.rm = T)) %&gt;% unique() country = sort(unique(mapdata$Country)) data = data.frame(Year = as.character(rep(seq(1900,2022), each = length(country))), Country = rep(country, 123)) data$Year = as.numeric(data$Year) data1 = data %&gt;% left_join(disaster_raw) data1[is.na(data1)] = 0 rawdata = left_join(mapdata,data1,by=c(&quot;Country&quot; = &quot;Country&quot;)) rawdata$Year = as.numeric(rawdata$Year) g2 = ggplot(rawdata, aes(x = long, y = lat, group = group))+ # the same as the setting with summary plot geom_polygon(aes(fill = log10(deaths)), color = &#39;black&#39;)+ transition_manual(frames = Year) + # use year as the animation parameter scale_fill_gradient(low = &#39;#FFF68F&#39;,high = &#39;#FC4902&#39;) + labs(title = paste(&#39;Year:&#39;,&#39;{current_frame}&#39;)) + # make the title changes among different plot ggdark::dark_theme_bw() animate(g2,fps = 3) g3 = ggplot(rawdata, aes(x = long, y = lat, group = group))+ # the same as the setting with summary plot geom_polygon(aes(fill = log10(damageadj)), color = &#39;black&#39;)+ transition_manual(frames = Year) + # use year as the animation parameter scale_fill_gradient(low = &#39;#FFF68F&#39;,high = &#39;#FC4902&#39;) + labs(title = paste(&#39;Year:&#39;,&#39;{current_frame}&#39;)) + # make the title changes among different plot ggdark::dark_theme_bw() animate(g3,fps = 3) Here, These two animations are a display of Death and Damage log pattern through different year. We can see that For Death data, It first appears to be large in Asia in the beginning of 20th century, and the from the late 20th century the number growth in Africa and South America. However, the damage shows the different pattern. It first appeared in America but then in late 20th century the damage in Asia(especially in China and India) become larger. 5.1.2 Analysis of the relationship between death and economic loss plot.data3 &lt;- disaster %&gt;% select(Country,Total.Deaths,Total.Damages.Adjusted,Continent) %&gt;% group_by(Country) %&gt;% summarize(Deaths = sum(Total.Deaths),Adjusted.Damages = sum(Total.Damages.Adjusted), disaster.Num =length(Total.Deaths),Continent = unique(Continent)) # plot 1 p3.1 &lt;- plot.data3 %&gt;% ggplot( aes(Deaths, Adjusted.Damages, size = disaster.Num, color=Continent)) + geom_point() + theme(legend.position = &quot;none&quot;,plot.margin = unit(c(1.5,1.5,1.5,1.5), &quot;lines&quot;)) + geom_text_repel(aes(y=Adjusted.Damages,x=Deaths,label=Country), col = &#39;black&#39;, size = 4, alpha = 0.7)+ labs(color = &#39;Continent&#39;, size = &quot;Disaster Frequency&quot;,y=&quot;Adjusted Damages&quot;) # plot 2 p3.2 &lt;-ggplot(plot.data3,aes(log(Deaths), log(Adjusted.Damages), size = disaster.Num, color=Continent, text = Country)) + geom_point() + theme(legend.position=&quot;none&quot;,plot.margin = unit(c(1.5,1.5,1.5,1.5), &quot;lines&quot;))+ geom_abline(intercept = 5,alpha=0.3)+ labs( x = &quot;Deaths(log)&quot;,y=&quot;Adjusted Damages(log)&quot;) # Set two plots on one canvas and share one legend. prow &lt;- plot_grid(p3.1,p3.2,labels = c(&quot;plot 1&quot;,&quot;plot 2&quot;),label_size = 12, label_x = 0, label_y = 0, hjust = -0.7, vjust = -0.4) legend_bottom &lt;- get_legend( p3.1 + guides(color = guide_legend(nrow = 2)) + theme(legend.position = &quot;bottom&quot;) ) plot_grid(prow, legend_bottom, ncol = 1, rel_heights = c(1, .15),labels = &quot;The Relation between Deaths and Damage between each Country&quot;) We calculated the cumulative economic losses, deaths, and occurrences of disasters for each country from 1900 to 2022, and plotted the economic losses and deaths as y and x, respectively, as a scatter plot figure 1, where the size of the dots correlates with the occurrence of disasters , and the colors are divided according to the continent (this data unifies South and North America into the Americas). Through figure 1, we can see that most of the countries are clustered in a small range, and only a few countries are very significant as outliers, such as the United States, Japan, China, India, Russia. However, these countries did not show a direct proportional trend in the number of deaths and economic losses. Among them, although the United States and Japan have fewer deaths, the economic losses are very large. While China, India and Russia suffered less economic losses, they have a large number of deaths. We believe that the reason for this phenomenon is that countries with developed economies will devote more resources to personnel protection, so even if the United States has a similar number of disasters as China, the death rate is far less than that of China. In contrast, the economic losses caused by disasters in these economically developed countries will be much greater than those in other countries. And countries like China, Russia and India are the most populous countries in the world, so thats why they have the highest number of disaster deaths. Then we log the deaths and economic losses, then make the scatter plot figure 2. From this graph, we can clearly see that each continent forms a certain cluster, and all countries have more economic loss ratios than death ratios (All countries are above line y=x). Countries in Africa have higher rates of death than economic losses compared to other continents. The second is Asian countries, which are generally distributed online, but the outlier countries, China, India and Bangladesh, are offline due to their large population. Japan is above the line because of its developed economy and small population. Above Asia are the countries of the Americas, Europe and Oceania. Among them, the United States economic loss rate far exceeds the death rate due to its developed economy, and Russia has become the only European country below the line because of its large population. Through this graph, we believe that the more developed the economy is, the greater the proportion of economic losses than deaths. In most developing countries in Africa, for example, the ratio of deaths to economic losses is higher than in the Americas and Europe. From this we can see that developed countries attach more importance to peoples protection. 5.2 COVID Data Exploration Our cleared COVID data have a column of Country and the summed total death since the start of COVID. We can see from the summary, there are 195 Countries. The maximum death is 993,999 and minimum is 0. The average death is 31991. Since Country is a multi-categorical variable, and Death is continuous variable, we will use Cleveland Dot Plot first to see its general idea. Then, we will use geometrical heatmap to do some spatial analysis. df_covid = read.csv(&quot;data/covid.csv&quot;) %&gt;% select(-X) summary(df_covid) ## Country.Region Total.Death ## Length:195 Min. : 0.0 ## Class :character 1st Qu.: 399.5 ## Mode :character Median : 3143.0 ## Mean : 31991.4 ## 3rd Qu.: 17212.0 ## Max. :993999.0 5.2.1 Cleveland Dot Plot df_covid %&gt;% arrange(desc(Total.Death)) %&gt;% head(50) %&gt;% mutate(&quot;Country.Region&quot; = fct_reorder(Country.Region, Total.Death)) %&gt;% ggplot(aes(x = Total.Death, y = Country.Region)) + geom_point(color = &quot;#D75D47&quot;, size = 2) + labs(title = &#39;COVID-19 Cumulative Death of Countries&#39;, y = &#39;&#39;, x = &quot;Total Death&quot;) Above plot showed the total death of the top 50 countries in descending order. As we can see, United States have the largest death number, which is close to 1000k. Besides the US, four other countries stood out: Brazil, India, Russia, and Mexico. These five countries have much more cases than others, one reason is they have comparatively large population size. Three out of five top countries are in America, and we think they might contaminated each other in some degree. Another other death level is from Peru to Turkey. In this level many countries are European countries with smaller population. The main reason that caused their total death could be related to policies. 5.2.2 Heatmap df_map = read.csv(&quot;data/Location.csv&quot;) df_covid %&gt;% left_join(df_map, by = c(&quot;Country.Region&quot; = &quot;Country&quot;)) %&gt;% ggplot(aes(x = long, y = lat, group = group, text = Country.Region)) + geom_polygon(aes(fill = Total.Death), color = &quot;#AAABAC&quot;) + scale_fill_gradient(low = &quot;#FBD588&quot;, high = &quot;#F55536&quot;) + labs(title = &quot;COVID-19 Cumulative Death World Heatmap&quot;, fill = &quot;Total Death&quot;, x = &quot;&quot;, y = &quot;&quot;) We plotted the heatmap to see some geographic pattern. As we can see most of the darker countries have a vast territory, and along with that larger population. Population could also be the reason African and European countries have comparatively pale colors. Another reason for Africa to have less death could be that COVID virus is afraid of heat. Island countries are less likely to contaminated by others, so they seems to have less deaths in general. 5.2.3 Time series for GDP Now we want to compare the ovid damage with the disaster damage. However the Covid is not a disaster that can show the economic damage clearly as some natural disaster as. We then try to develop a GDP decrease by predicting a no Covid possible GDP and compare the difference. First we need to find out the target countries and then making predictions. target.Country = c(&#39;France&#39;,&#39;Italy&#39;,&#39;Germany&#39;,&#39;Russia&#39;,&#39;UK&#39;,&#39;US&#39;,&#39;Canada&#39;,&#39;Brazil&#39;,&#39;Peru&#39;,&#39;Australia&#39;,&#39;New Zealand&#39;,&#39;China&#39;,&#39;India&#39;,&#39;Japan&#39;, &#39;Iraq&#39;, &#39;Saudi Arabia&#39;,&#39;South Africa&#39;,&#39;Egypt&#39;, &#39;Ethiopia&#39;, &#39;Uganda&#39;) GDP = read.csv(&#39;data/GDP.csv&#39;) %&gt;% select(-X) %&gt;% filter(Country.Name %in% target.Country) %&gt;% pivot_longer(cols = X1960:X2020, values_to = &#39;gdp&#39;, names_to = &#39;year&#39;) %&gt;% mutate(year = as.numeric(substr(year, 2, 5))) Now first see if there is a trend or seasonal effect ggplot(GDP, aes(year, gdp))+ geom_line(aes(color = Country.Name)) I dont think that there is a seasonal effect, but there is obviously a trend. Then we try to use difference method to get a stationary time series data for each country. diff = c() for(c in target.Country){ gdp = GDP %&gt;% filter(Country.Name == c &amp; !is.na(gdp)) gdp.dif1&lt;-diff(gdp$gdp) gdp.dif2&lt;-diff(gdp$gdp,1,2) a = fUnitRoots::adfTest(gdp.dif1) b = fUnitRoots::adfTest(gdp.dif2) diff = c(diff, ifelse(a@test$p.value&gt;b@test$p.value, 1, 2)) } diff ## ## 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 So we are more likely to do second order difference at this time. After several tries, we find that ARIMA(1,2,0) best fit the data forecastgdp = c() for(c in target.Country){ gdp = GDP %&gt;% filter(Country.Name == c &amp; !is.na(gdp) &amp; year!=2020) gdparima = arima(gdp$gdp,order=c(1,2,0)) forecastgdp = c(forecastgdp, forecast(gdparima,h=1)$mean) } Since weve already get the estimate, we want to see the difference between real data and the estimate GDPplot = GDP %&gt;% left_join(data.frame(est = forecastgdp, Country.Name = target.Country)) %&gt;% mutate(est = ifelse(year!=2020, gdp, est), Country.Name = fct_relevel(Country.Name, c(&#39;France&#39;,&#39;Italy&#39;,&#39;Germany&#39;,&#39;Russia&#39;,&#39;UK&#39;,&#39;US&#39;,&#39;Canada&#39;,&#39;Brazil&#39;,&#39;Peru&#39;,&#39;Australia&#39;, &#39;New Zealand&#39;,&#39;China&#39;,&#39;India&#39;,&#39;Japan&#39;, &#39;Iraq&#39;, &#39;Saudi Arabia&#39;,&#39;South Africa&#39;, &#39;Egypt&#39;, &#39;Ethiopia&#39;, &#39;Uganda&#39;))) %&gt;% filter(year &gt; 2013) col = c(estimate = &#39;red&#39;, real = &#39;black&#39;) ggplot(GDPplot)+ geom_line(aes(year, est, col = &#39;estimate&#39;))+ geom_line(aes(year, gdp, col = &#39;real&#39;))+ facet_wrap(~Country.Name, scales = &quot;free_y&quot;, nrow = 10)+ scale_colour_manual(name = &quot;Type&quot;, values = col) As we can see from the plot, all the countries suffered from a GDP decrease in 2020 except China, Egypt, Ethiopia and Uganda. For China, the reason is that it use a compulsory policy to prevent the Covid from spreading thus control the cases. For the African countries, they are now going through a rapid economic increasing which can not be shown by the time series model, so that their real value are larger than the estimate value. disaster = read.csv(&#39;data/disaster.csv&#39;) %&gt;% select(-X) %&gt;% filter(Country %in% target.Country) %&gt;% group_by(Country, Continent) %&gt;% summarize(Damage = sum(Total.Damages.Adjusted)) coviddamage = GDPplot %&gt;% filter(year==2020) %&gt;% mutate(diff = est - gdp) %&gt;% left_join(disaster, by = c(&#39;Country.Name&#39;=&#39;Country&#39;)) g = ggplot(coviddamage, aes(x=log(Damage), y = log(diff+abs(min(coviddamage$diff))), text = Country.Name))+ geom_point(aes(color = Continent), size = 3)+ labs(x = &#39;Damage(log)&#39;, y = &#39;The GDP difference(Scaled log)&#39;, title = &#39;The damage from Covid vs. other Disaster&#39;) ggplotly(g) ## Warning: Use of `coviddamage$diff` is discouraged. Use `diff` instead. As we can see from the plot, The countries from Oceania forms a cluster under the line which means that the Damage from other Disaster is far more larger than the Covid damage. Its because These countries are far from mainland and will not that suffer from covid. For African countries, they are really suffer from other disease like Ebola instead of Covid. For Western and Mid Asian countries, they are suffering from an economic crisis so the GDP decrease cant really represent the true Covid damage. "],["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component Here we construct a shiny interactive plot to show the Year pattern of GDP, Damage and Deaths on the world map. We can see the geographical patterns by using it. https://howardch.shinyapps.io/Shiny/ "],["conclusion.html", "Chapter 7 Conclusion 7.1 Disaster Data 7.2 Comparing Disaster Damage and Covid", " Chapter 7 Conclusion 7.1 Disaster Data Through the above analysis of disasters, we can find the following points. First of all, there are more natural disasters than technological disasters in this dataset, and we think its because of a problem with its data collection process. It did not include disasters caused by technology such as war, firearm death, etc.. We guessed that it may be because this type of data is difficult to count. Given the above situation, we found that in terms of the frequency of disasters, technological disasters are all very high. But if we look at deaths and economic losses, natural disasters are firmly at the forefront. The reason for this, we believe, may be that the scale of natural disasters far exceeds that of technological disasters, so although technological disasters occur frequently, their destructive power is still less than the natural disasters. Of course, for the overall trend, deaths and economic losses are still positively correlated with the frequency of disasters. Secondly, the more developed countries are more in place for the protection of personnel. 7.2 Comparing Disaster Damage and Covid Based on our analysis, we want to see some pattern between COVID and other disaster for different countries. As we discovered, most of the developed countries have similar or the same pattern for COVID and other disaster. But for some of the developing countries and countries from Oceania, its not the case. Its because of both geographical and economical reasons. COVID is actually the reason we are interested in disaster analysis in the first place. It has had a huge impact in our daily life and in economic world. But after getting the disaster data, an interesting finding is that for disaster caused by infectious diseases like COVID, the damage is usually 0, because these type of disaster does not really have damage to our tangible assets like houses or cars, and other emotional damage, potential damage, and damage to our intangible assets are hard to count by money. We in the end used GDP as an indicate to COVID economic damage, and the number is huge, which makes us wonder if there are huge losses from former diseases that were not accounted for. The things we have lost from all disasters are far beyond the counting from this dataset. It is important to study and analyze disasters - the possible causes and patterns of natural disasters and the reasons for technology disasters - so that we can better maintain the environment of the world we lived in. "]]
